<!DOCTYPE html><html><head><title>VACC grid search scripting</title><meta charset="UTF-8"><meta name="robots" content="index, follow"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="author" content="Steven Baldasty"><meta property="og:image" content><link rel="icon" type="image/x-icon" href="/logo.png"><link rel="stylesheet" href="/site.css"></head><body><div class="brand"><img src="/logo.png" title="Website logo" alt="Three stacked blue boxes with binary digits on them" width="86" height="86"><div class="exposition"><div class="title">Bit flipping laboratory &amp; Personal website</div><div class="caption">No sneaky cookies haunt these pages, but whether someone tracks you I do not know. Information flows through many channels, and every action leaves a trace.</div></div></div><div class="nav"><a href="/">Home</a><a href="/article/">Articles</a><a href="/media/">Media</a></div><hr><div class="article"><div class="date"> 2025-03-11 </div><div class="summary"> Grid search implementation on the University of Vermont's supercomputing cluster. Overview, code snippets, design decisions, and open questions. I don't think we're in AWS land anymore. Thanks to the VACC team for their help with the project. </div><h1>VACC grid search scripting</h1><p> The <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> is a supercomputing cluster at <a href="https://uvm.edu" target="blank_">UVM</a>. Authorized students, faculty, and other affiliates can run computational tasks that would be too expensive for a laptop there. Access requires a <a href="https://uvm.edu" target="blank_">UVM</a> issued identity called a <a href="https://account.uvm.edu/" target="blank_">NetID</a>, and an <a href="https://www.uvm.edu/vacc/request-allocation" target="blank_">account</a> for billing purposes. In my experience the account usually comes from an advisor or from the instructor of a class, and every student should already have a <a href="https://account.uvm.edu/" target="blank_">NetID</a>. </p><p> The <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> has a graphical user interface called <a href="https://ondemand.vacc.uvm.edu/" target="blank_">OnDemand</a> which may better suit simple manual tasks, but here I focus on building blocks for automation using the Linux command line. I run a Linux distribution on my laptop that is based on <a href="https://www.debian.org/" target="blank_">Debian</a>, but MacOS, Windows, or other varieties of Linux should suffice with minimal adaptation; most of the code just runs on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> anyway. The idea is to upload a <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> project to the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>, queue jobs using the <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> scheduling system, and download the results when the jobs finish. </p><h2>Connecting</h2><p> Interacting with the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> requires a secure channel of communication in the form of a <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> connection to one of its login nodes behind <b>login.vacc.uvm.edu</b>. The login nodes unfortunately do not support public key authentication, only authentication by username and password. The username is a valid <a href="https://account.uvm.edu/" target="blank_">NetID</a>, and the password is the password associated with that <a href="https://account.uvm.edu/" target="blank_">NetID</a>. I run this code on my laptop. I use environment variables, but they aren't necessary. </p><pre class="snippet"># Host is the VACC login node
HOST=${LOGIN_NODE}

# Assuming the username is bob
NETID=bob

# Install ssh and scp clients
sudo apt install openssh-client

# Test the connection
ssh $NETID@$HOST

# If working then exit when done
exit</pre><p> The first time I connect, <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> is unable to establish the host's authenticity and prompts me to confirm the connection by entering <kbd>yes</kbd>. This prompt causes the <a class="tech" href="https://www.cyberciti.biz/faq/noninteractive-shell-script-ssh-password-provider" target="blank_" title="Password forwarder for ssh and scp">sshpass</a> utility I introduce next to fail, so I get it out of the way now; the prompt will not reappear for subsequent connection attempts. Or better yet, perhaps there is a switch to circumvent the authenticity check altogether? Also, the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> documentation suggests I must be on campus or on the university's VPN to connect, but so far I have had no issues. </p><p> Authentication by username and password has the drawback that any scripts I eventually write will prompt me for my password every time they need to connect. One workaround <strong>not without security risks</strong> is to put the password in a local file. I can then use <a class="tech" href="https://www.cyberciti.biz/faq/noninteractive-shell-script-ssh-password-provider" target="blank_" title="Password forwarder for ssh and scp">sshpass</a> to feed the password to <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> or <a class="tech" href="https://snapshooter.com/learn/linux/copy-files-scp" target="blank_" title="Copies files between computers securely">scp</a>. </p><pre class="snippet"># Create a directory for password file
mkdir $HOME/.sshpasswds

# Path to file containing password
PWPATH=$HOME/.sshpasswds/uvm

# Save password in a file
vim $PWPATH

# Optionally lock down access somewhat
chmod 400 $PWPATH

# Install sshpass if not yet installed
sudo apt install sshpass

# Optionally test ssh with sshpass
sshpass -f $PWPATH ssh $NETID@$HOST pwd</pre><p> The optional test on the last line outputs my home directory on the login node. Then <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> lands me back on my laptop right away when the command finishes. See also this <a href="https://www.cyberciti.biz/faq/noninteractive-shell-script-ssh-password-provider" target="blank_">tutorial</a> for more about <a class="tech" href="https://www.cyberciti.biz/faq/noninteractive-shell-script-ssh-password-provider" target="blank_" title="Password forwarder for ssh and scp">sshpass</a> and its switches. </p><p> An inconvenience I have not solved is that the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> sometimes forces a cooldown period if I connect too many times. It doesn't really happen during normal use, but it can happen during the iterative process of debugging a script. I recall reading somewhere about a way to bundle many <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> and <a class="tech" href="https://snapshooter.com/learn/linux/copy-files-scp" target="blank_" title="Copies files between computers securely">scp</a> operations into a single remote session, which may help avoid this. </p><h2>Project organization</h2><p> The <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> community maintains an enormous number of <a href="https://vinayak-hegde.medium.com/top-10-tools-for-creating-isolated-environments-152d665640f2" target="blank_">complicated tools</a> to manage python installations, project dependencies, and version conflicts. Different projects use different tools. The <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> strongly encourages projects to use <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a>, so I add an <code>environment.yaml</code> file to my project, defining the <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> environment; but to support the use of my project without <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a>, I list all my <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> package dependencies in a <code>requirements.txt</code> file like so. </p><pre class="snippet">mpyc==0.10
numpy==2.0.1
pandas==2.2.2</pre><p> Then the <code>environment.yaml</code> file for <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> essentially becomes a thin wrapper around <a class="tech" href="https://github.com/pypa/pip" target="blank_" title="Standard python package manager">pip</a>. The <code>environment.yaml</code> file tells <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> to install <a class="tech" href="https://github.com/pypa/pip" target="blank_" title="Standard python package manager">pip</a> and then use it to install the package dependencies from <code>requirements.txt</code>. Another benefit of this approach is the certainty of having access to all the packages. Not all packages are available in <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> natively. </p><pre class="snippet">name: myproject
channels:
  - defaults
dependencies:
  - python=3.11
  - pip
  - pip:
    - -r requirements.txt</pre><p> I also like to install the project itself as a package. Then if the project had multiple source files, I could freely import them from each other without worrying about their relative paths. Installing the project as a package also helps with unit testing. Different approaches are possible. I use a <code>pyproject.toml</code> file. This configuration works because all my source code is in a <code>src</code> directory in my project, and I do not have any nested source directories. </p><pre class="snippet">[project]
name = &#34;src&#34;
version = &#34;0.1&#34;

[build-system]
requires = [&#34;setuptools&#34;]
build-backend = &#34;setuptools.build_meta&#34;

[tool.setuptools]
packages = [&#34;src&#34;]</pre><p> I install the project as a package in <i>editable mode</i>. Editable mode means that changes to the source code get immediately reflected in the installed package: a very useful feature for iterative development. I do this step locally on my laptop, as well as on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>. </p><pre class="snippet">python -m pip install -e .</pre><p> At risk of further complicating an already complicated process, I use <a class="tech" href="https://github.com/pyenv/pyenv" target="blank_" title="Python version manager and manager of other managers">pyenv</a> on my laptop to isolate from each other all the versions of <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a>, build tools, and package dependencies which the projects I work on require. I create a new environment with <a class="tech" href="https://github.com/pyenv/pyenv" target="blank_" title="Python version manager and manager of other managers">pyenv</a>, and add a <code>.python-version</code> file to my project containing the name of the environment. My <a class="tech" href="https://ss64.com/bash/bash.html" target="blank_" title="Common shell for Linux">bash</a> shell detects this file when I enter the project directory, and has <a class="tech" href="https://github.com/pyenv/pyenv" target="blank_" title="Python version manager and manager of other managers">pyenv</a> activate the appropriate environment automatically. Conversely when I leave the project directory, <a class="tech" href="https://github.com/pyenv/pyenv" target="blank_" title="Python version manager and manager of other managers">pyenv</a> deactivates the environment again. </p><h2>The scripts</h2><p> The remaining code snippets fit nicely into scripts. I keep the scripts related to my project in the <code>script</code> directory of my project. Some scripts are for running on my laptop, and others are for running on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>. Some scripts are specific to projects like mine that are based on a grid search. </p><table><tr><th>Script</th><th>Purpose</th><th>Target</th></tr><tr><td><code>copy_project.sh</code></td><td>Copies the project from my laptop to the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>. Recreates a <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> environment on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> with the project's stated <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> package dependencies as needed.</td><td>Laptop</td></tr><tr><td><code>copy_output.sh</code></td><td>Optionally verifies none of the project's jobs are running on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>. Deletes and recreates the output directory on my laptop. Recursively copies the results directory from <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> to my laptop.</td><td>Laptop</td></tr><tr><td><code>vacc_init_env.sh</code></td><td>Recreates a <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> environment on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> with the project's stated <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> package dependencies as needed.</td><td>VACC</td></tr><tr><td><code>set_vars.sh</code></td><td>Sets common project related environment variables for use in other scripts.</td><td>Both</td></tr><tr><td><code>vacc_batch.sh</code><br><i><small>Grid search only</small></i></td><td>Creates many small <a class="tech" href="https://ss64.com/bash/bash.html" target="blank_" title="Common shell for Linux">bash</a> scripts, each of which submits a <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> job using particular experimental parameters when run. Projects searching over multiple grids may have multiple batch scripts.</td><td>VACC</td></tr><tr><td><code>vacc_job.sh</code><br><i><small>Grid search only</small></i></td><td>Loads the project's <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> environment. Calls the main <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> script, supplying appropriate command line arguments from environment variables.</td><td>VACC</td></tr><tr><td><code>vacc_run_all.sh</code><br><i><small>Grid search only</small></i></td><td>Runs all the <a class="tech" href="https://ss64.com/bash/bash.html" target="blank_" title="Common shell for Linux">bash</a> scripts created by <code>vacc_batch.sh</code> at once, thereby submitting many jobs to SLURM.</td><td>VACC</td></tr></table><p> A number of environment variables are shared across the scripts, both the scripts that run on my laptop and those that run on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>. Many of these we have seen and used already. I add them to <code>set_vars.sh</code> and use <a class="tech" href="https://ss64.com/bash/source.html" target="blank_" title="Runs scripts in the current bash shell">source</a> at the beginning of the other scripts to make them available. </p><pre class="snippet"># Host is the VACC login node
HOST=${LOGIN_NODE}

# Assuming the username is bob
NETID=bob

# Name of the project
PRJNAME=project

# Where project lives locally
PRJPATH=$HOME/src/$PRJNAME

# Path to password (whatever you choose)
PWPATH=$HOME/.sshpasswds/uvm

# Where output lives on VACC
OUTPATH=out

# Where output will be analyzed on laptop
ANPATH=$HOME/analysis

# Conda module
CONMOD=python3.11-anaconda/2023.09-0</pre><p> The last environment variable determines what version of <a class="tech" href="https://www.python.org/" target="blank_" title="Fairly ubiquitous programming language">python</a> the project will run under. To see what options are available on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>, I open a <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> session there, run <code>module avail</code>, note the modules that start with <code>python</code>, and press <kbd>q</kbd> to exit. <h2>Uploading the project</h2><p> The operating system package that installs <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> also comes with a utility called <a class="tech" href="https://snapshooter.com/learn/linux/copy-files-scp" target="blank_" title="Copies files between computers securely">scp</a> for copying files securely between computers. Its syntax is similar to <a class="tech" href="https://ss64.com/bash/cp.html" target="blank_" title="Copies files and directories locally">cp</a>, but with either the source or destination prefixed by the username and host. The main responsibility of <code>copy_project.sh</code> is to upload the project to my home directory on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> using <a class="tech" href="https://snapshooter.com/learn/linux/copy-files-scp" target="blank_" title="Copies files between computers securely">scp</a>. The <code>-r</code> switch recursively uploads any subdirectories the project has. </p><pre class="snippet"># Delete any older version of the project on the VACC
CMD=&#34;rm -rf $PRJNAME&#34;
sshpass -f $PWPATH ssh $NETID@$HOST &#34;$CMD&#34;

# Copy project to VACC
sshpass -f $PWPATH scp -rC $PRJPATH $NETID@$HOST:</pre><p> The <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> uses <a class="tech" href="https://lmod.readthedocs.io/en/latest/080_hierarchy.html" target="blank_" title="Manages available Lmod modules">module</a> to install <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a>, and then uses <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> to install all the project's dependencies. I add all these installation steps to <code>vacc_init_env.sh</code>. </p><pre class="snippet"># Clear out any loaded modules
module purge

# Load python and anaconda
module load ${CONMOD}

# Put anaconda binaries on the path
source ${ANACONDA_ROOT}/etc/profile.d/conda.sh</pre><p> The <code>vacc_init_env.sh</code> script goes on to configure the <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> environment. I recreate the environment only if necessary, and install without prompting for confirmation. The <code>--prune</code> switch removes any dependencies I may have removed from my project. </p><pre class="snippet"># Create the environment if needed
if ! conda env list | grep $PRJNAME &gt;/dev/null 2&gt;&amp;1; then
    yes | conda create --name $PRJNAME python=3.11
fi

# Update the environment with latest project dependencies
conda env update --file environment.yaml --prune
conda activate $PRJNAME

# Install ourself locally
python -m pip install -e .</pre><p> One option is to run <code>vacc_init_env.sh</code> just once from a <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> session at the outset, or to perform the steps manually; but I prefer to call <code>vacc_init_env.sh</code> over <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> from <code>copy_project.sh</code>. In this way I recreate the environment every time I copy a new version of the project to the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> and never worry about whether the environment under which the project will run reflects any changes I recently made to its dependencies. </p><pre class="snippet">CMD=&#34;bash $PRJNAME/script/vacc_init_env.sh&#34;
sshpass -f $PWPATH ssh $NETID@$HOST &#34;$CMD&#34;</pre><p> How this works is that when I run <code>copy_project.sh</code> on my laptop, the <code>vacc_init_env.sh</code> script gets copied to the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> along with the rest of the project. That is what makes it available to call there. Of course it is important remember to <a class="tech" href="https://ss64.com/bash/source.html" target="blank_" title="Runs scripts in the current bash shell">source</a> the <code>set_vars.sh</code> script at the beginning of all these other scripts. </p><h2>Starting jobs</h2><p> Different projects use the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> in different ways. Some projects only start a single job that runs within the maximum allotted time. Other projects are best conceptualized as a single job, but if a single job cannot finish within the maximum allotted time, it must save its progress and resume in a subsequent job, and so on. The project I describe is unlike these. It is a grid search: many jobs run independently of each other, and ideally simultaneously, all using the same code but parameterized in slightly different ways. The <i>grid</i> is like a high dimensional rectangle of all the combinations of parameters under which the job should run. </p><p> The <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> uses the <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> job scheduler to manage jobs. This means that submitted jobs do not necessarily start right away, but rather enter a job queue. <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> accepts job submissions using the <a class="tech" href="https://slurm.schedmd.com/sbatch.html" target="blank_" title="Queues jobs in the slurm scheduling system">sbatch</a> utility, and later starts them once the resources they need are available on the supercomputing cluster. </p><p> While submitting jobs from my laptop is possible by sending one-off commands across individual <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> sessions as shown previously, I prefer doing it directly on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> from an interactive <a class="tech" href="https://www.uvm.edu/vacc/docs/start_guide/ssh" target="blank_" title="Opens secure shells on remote systems">ssh</a> session. I also prefer not submitting jobs directly from <code>vacc_batch.sh</code>, but rather having <code>vacc_batch.sh</code> create many small <a class="tech" href="https://ss64.com/bash/bash.html" target="blank_" title="Common shell for Linux">bash</a> scripts, each of which submits a job when run. This allows several advantages: <ul> <li><p>I can carefully review the actual <a class="tech" href="https://slurm.schedmd.com/sbatch.html" target="blank_" title="Queues jobs in the slurm scheduling system">sbatch</a> commands that will submit my jobs. I can see how many jobs there are. I can see what the environment variables in each job are. </p></li><li><p> I have the full flexibility of Linux filesystem commands to control what jobs get run, and which will not. I can easily rerun individual failed jobs. </p></li><li><p> I can still run all the job submission scripts at once with a simple script like <code>vacc_run_all.sh</code>, so this extra step of creating individual submission scripts adds no real inconvenience. </p></li></ul><p> The <code>vacc_batch.sh</code> script starts by getting the directory it lives in. This is important so it knows the correct fully qualified path to use for the actual script that runs the job, which lives in the same directory. </p><pre class="snippet">SCRIPT_DIR=$(dirname &#34;$(realpath &#34;$0&#34;)&#34;)</pre><p> I maintain variables for the name of the batch and a number I assign sequentially to the jobs within that batch. I include the batch name and job number in the filename of the job's <i>submission script</i>, in the filename of the job's <i>output log</i>, and in the filename of whatever <i>result</i> the job produces. This allows easy cross-referencing between these three files. </p><pre class="snippet">batch=&#34;example_batch&#34;
job=0</pre><p> This version of my script assumes all the jobs in the batch require the same resources to run. The script will need to be more sophisticated if this is not the case. Another way to solve that problem is to use multiple batches for the different resource requirements. </p><p> The nested loops iterate over all the combinations of parameter values. They <i>export</i> the parameter values for use by the job submission script. The submission scripts get created in a <code>stage</code> directory in my home directory on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a>. </p><pre class="snippet"># Parameter ranges
p1s=(&#34;1&#34; &#34;2&#34; &#34;3&#34; &#34;4&#34;)
p2s=(&#34;a&#34; &#34;b&#34; &#34;c&#34;)

for p1 in &#34;${p1s[@]}&#34;;
do
  for p2 in &#34;${p2s[@]}&#34;;
    ((job++))
    outfile=&#34;$HOME/stage/${batch}_$job.sh&#34;
    echo &#34;sbatch
      --nodes=1
      --time=12:00:00
      --ntasks=1
      --cpus-per-task=1
      --mem=16G
      --job-name=${batch}_$job
      --output=${batch}_$job.out
      \&#34;--export=batch=$batch,job=$job,p1=$p1,p2=$p2\&#34;
      \&#34;$SCRIPT_DIR/vacc_job.sh\&#34;&#34; &gt; &#34;$outfile&#34;
  done
done</pre><p> The submission scripts all call <code>vacc_job.sh</code>, which assumes the <code>batch</code> environment variable is set to the name of the batch, that <code>job</code> is set to the job number, and that the experimental parameters <code>p1</code> and <code>p2</code> are set to their desired values. With that, <code>vacc_job.sh</code> loads the project's <a class="tech" href="https://docs.conda.io/en/latest/" target="blank_" title="Python package manager, environment manager, and build system">conda</a> environment and runs <code>main.py</code> with the appropriate command line arguments. I do not show the python script here, but it should use <a class="tech" href="https://docs.python.org/3/library/argparse.html" target="blank_" title="Parser for command line arguments">argparse</a> or something similar to read the command line arguments. </p><pre class="snippet"># Load conda environment
module load python3.11-anaconda/2024.02-1
source ${ANACONDA_ROOT}/etc/profile.d/conda.sh
conda activate mpyc-random-forest

cd $HOME/$PRJNAME
python src/main.py \
  --batch=$batch \
  --job=$job \
  --p1=$p1 \
  --p2=$p2</pre><p> As mentioned, a convenient way to run all the generated submission scripts at once like <code>vacc_run_all.sh</code> will be helpful. </p><pre class="snippet">for script in $HOME/stage/*.sh; do
  bash &#34;$script&#34;
done</pre><p> This script runs all the <a class="tech" href="https://ss64.com/bash/bash.html" target="blank_" title="Common shell for Linux">bash</a> scripts it finds in the <code>stage</code> directory. </p><h2>Downloading the output</h2><p> The last step is to copy its output back to my laptop with <code>copy_output.sh</code> for analysis, but how can I know if the batch finished? <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> can send email notifications when individual jobs finish, but getting alerted when a whole batch finishes would require a long-running script, as far as I can tell. I instead determined whether the batch finished with a simple manual check. </p><pre class="snippet">sshpass -f $PWPATH ssh $NETID@$HOST &#34;squeue --me&#34;</pre><p> The check shows any <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> jobs associated with my user. If the list is empty, I can go ahead and copy the batch output. The check is good enough for my purposes, but it has weaknesses that could hinder automation: </p><ul><li><p> I may be running other jobs on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> besides those in the batch. Then the list would contain jobs even though the batch finished. Luckily <a class="tech" href="https://ss64.com/bash/grep.html" target="blank_" title="Distributed version control system">grep</a> can help here because I prefixed the job names with the batch name. Perhaps one of the many available <a class="tech" href="https://slurm.schedmd.com/squeue.html" target="blank_" title="Displays the slurm job queue">squeue</a> switches could also help. </p></li><li><p> The check cannot distinguish between jobs that finished because they succeeded, and jobs that finished because they failed. Even though <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> has job statuses for <i>Success</i> and <i>Failure</i>, it forgets the jobs shortly after the jobs finish. Possibly this has more to do with the configuration of <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> on the <a href="https://www.uvm.edu/vacc" target="blank_">VACC</a> than with <a href="https://slurm.schedmd.com/documentation.html" target="blank_">SLURM</a> generally. My jobs only write output when they succeed, so instead I identify job failures by the conjunction of an empty queue and missing output files. </p></li></ul><p> Beyond the question of whether the batch finished (and finished successfully), <code>copy_output.sh</code> is a straightforward process of preparing space for the output files on my laptop, and copying them over with the <a class="tech" href="https://snapshooter.com/learn/linux/copy-files-scp" target="blank_" title="Copies files between computers securely">scp</a> utility. </p><pre class="snippet"># Remove any old results
rm -rf $ANPATH

# Recreate results
mkdir $ANPATH

# Download results to directory
sshpass -f $PWPATH scp -rC $NETID@$HOST:$OUTPATH $ANPATH</pre><p> And with the experimental results on my laptop, the joy of data analysis can begin! </p></div><hr class="top-gapped"><div class="author"><div class="exposition"><div class="title">Steven Baldasty</div><div class="caption">Proud father, Barefoot runner, Chocolate enthusiast, Seasoned software engineer, Starry eyed PhD student, Novice human</div></div><img src="/selfie.png" title="Sketch courtesy of my daughter" alt="Handsome brown haired man with glasses" width="80" height="88"></div></body></html>