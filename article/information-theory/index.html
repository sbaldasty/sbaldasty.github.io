<!DOCTYPE html>
<html>
<head>
  <title>My document title</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="/site.css">
</head>
<body>
  <hr>
  <div class="brand">
    <img src="/logo.png" alt="Logo">
    <div>
      <div class="title">Bit flipping laboratory &amp; Personal website</div>
      <div class="caption">No sneaky cookies haunt these pages, but whether someone tracks you I do not know. Information flows through many channels, and every action leaves a trace.</div>
    </div>
  </div>
  <div class="nav">
    <a href="/">Home</a>
    <a href="/article-list/">Articles</a>
    <a href="/media/">Media</a>
  </div>
  <hr>
  
    <div class="article-date">
        <div>2023-08-09</div>
    </div>
    <h1>Museums about information theory</h1>
    <p>
        
    I took an information theory class at UVM, and later visited two information theory related museums: the Museum of Printing and the New Hampshire Telephone Museum.

    </p>
    
    <h2>Information theory</h2>
    <p>Imagine having a piece of text, audio, images, video, or other media. Now imagine a scenario where that media gets sent to another place or to a future time. We encode the media as a sequence of bits called a <i>message</i>. We set aside any notion of meaning the message represents. We send the message through a <i>channel</i> such as a telephone cable or hard drive. We recover the media by decoding the message. Important considerations arise. How for efficiency can we send the message with the fewest number of bits? Conversely how can we add redundancy to protect the message from corruption due to noise in the channel?</p>

    <p>A related question is how to measure the amount of information in a message. A <i>combinatorial</i> approach counts how many symbols the message contains. The symbols are usually bits. <i>Shannon Entropy</i> also consider the predictability of the next symbol given the symbols that have appeared before. <i>Kolmogorov Complexity</i> asks instead, how long is the shortest computer program that generates the sequence? Information theory as we studied it mostly considered Shannon Entropy.</p>

    <h2>A history, a theory, a flood</h2>

    <p>One of the supplementary resources for the class was a less technical book called <i>The Information: A History, A Theory, A Flood</i> by James Gleik. The book tells the story of humanity's rapidly accelerating dance with information with countless anecdotes from ancient history to the present day. It tells how each advance brought profound societal changes and affected the thinking of everyday people in big ways. A few of my favorites were</p>

    <ul>
    <li><p>How in Africa, drums using two pitches could spread news between villages. African drumming was for centuries a long-unparalleled means of communication over enormous distances.</p>
    <li><p>How writing emerged from ancient spoken language and made it possible for information to pass unaltered through space and time.</p>
    <li><p>How in the American West during the early days of telephony, landowners formed a large improvised telephone network through the barbed wire of their fences.</p>
    <li><p>How Robert Cawdrey compiled the first English dictionary, and communicated the notion of what a dictionary even is to the public.</p>
    <li><p>How before people harnessed electricity, Charles Babbage designed a mechanical general purpose computer; and how his collaborator Ada Lovelace worked out how to solve problems with his imaginary computer, and is widely considered the very first computer programmer.</p>
    <li><p>How Claude Shannon and other brilliant thinkers like Andrei Kolmogorov formalized information theory, and laid the foundations for modern electronic communication.</p>
    </ul>

    <p>Spending time with historical artifacts from the worlds of printing and telephony naturally brought to life for me a large important swath of that history.</p>

    
    <div class="gallery">
    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    </div>


    <h2>The Museum of Printing</h2>

    <p>The Museum of Printing is in Haverhill, MA. It has fascinating hands-on exhibits and knowledgeable staff who are happy to answer questions and offer guided tours. From its About Page,</p>

    <blockquote>The Museum of Printing is dedicated to preserving the rich history of the graphic arts, printing and typesetting technology, and printing craftsmanship. In addition to many special collections and small exhibits, the Museum contains hundreds of antique printing, typesetting, and bindery machines, as well as a library of books and printing-related documents.</blockquote>

    <p>Someone there even walked me through the process of making a cast of my name from a light molten metal in the same way an operator would prepare a page for mass production. After printing enough copies, they could melt the cast down again and reuse the metal for another page, but I got to keep my name!</p>

    
    <div class="gallery">
    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    </div>


    <h2>The New Hampshire Telephone Museum</h2>

    <p>The New Hampshire Telephone Museum is in Warner, NH. I recommend visiting the museum to anyone interested learning about the history of telegraphs and telephones or seeing firsthand some of the fascinating artifacts on which our communications infrastructure is built, past and present. It also have several hands-on demos: telegraphs, manual switchboards, automated switchboards, and early coin operated telephones. There is a whole room dedicated to the life of Alexander Bell.</p>

    
    <div class="gallery">
    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    
    
    &lt;p&gt;A photo will go here...&lt;/p&gt;

    </div>


    <h2>Reflections</h2>

    <p>Among the final ideas presented in <i>The Information: A History, A Theory, A Flood</i> is that when information is scarce and difficult to access, then it is expensive; but when information is plentiful and easy to access then attention is expensive. In the same way that most people in the past were unable to understand the ways in which new information technologies would affect their lives and minds, I too am unlikely to understand the ways in which new information technologies will affect my life and mind, and those of the generations that follow.</p>


    <h2>References</h2>
    <ul>
        
    
    <li>
    <div><b><a href="https://www.amazon.com/Information-History-Theory-Flood/dp/1400096235">The Information: A History, A Theory, A Flood</a></b></div>
    <div>Amazon page for a good book about the humanity&#39;s history with information.</div>

    
    <li>
    <div><b><a href="https://www.museumofprinting.org/">Museum of Printing homepage</a></b></div>
    <div>Includes location, hours of operation, events calendar, membership information, volunteer opportunities, and exhibit pictures.</div>

    
    <li>
    <div><b><a href="https://www.nhtelephonemuseum.org/">New Hampshire Telephone Museum homepage</a></b></div>
    <div>Includes location, hours of operation, membership information, and online store.</div>

    
    <li>
    <div><b><a href="https://www.tandfonline.com/doi/abs/10.1080/00207166808803030">Three Approaches to the Quantitative Definition of Information</a></b></div>
    <div>Andrei Kolmogorov&#39;s paper about different perspectives on how to measure an &lt;i&gt;amount&lt;/i&gt; of information.</div>


    </ul>

</body>
</html>